import hashlib
import json
import os
import time
import wave
from collections import OrderedDict
from pathlib import Path
from typing import Any

import numpy as np
import streamlit as st
import streamlit.components.v1 as components
from streamlit_mic_recorder import mic_recorder

from mypylib.authenticate import DbInterface
from mypylib.azure_speech import (
    pronunciation_assessment_with_content_assessment,
    synthesize_speech_to_file,
)
from mypylib.azure_translator import language_detect
from mypylib.constants import CEFR_LEVEL_MAPS, LAN_MAPS, TOPICS
from mypylib.google_api import init_vertex, generate_english_topics
from mypylib.html_constants import STYLE, TIPPY_JS
from mypylib.nivo_charts import gen_radar
from mypylib.word_utils import audio_autoplay_elem

# region è®¤è¯åŠåˆå§‹åŒ–

if "user_id" not in st.session_state:
    st.session_state["user_id"] = None

if "dbi" not in st.session_state:
    st.session_state["dbi"] = DbInterface()

if not st.session_state.dbi.is_service_active(st.session_state["user_id"]):
    st.error("éä»˜è´¹ç”¨æˆ·ï¼Œæ— æ³•ä½¿ç”¨æ­¤åŠŸèƒ½ã€‚")
    st.stop()

if st.secrets["env"] in ["streamlit", "azure"]:
    if "inited_vertex" not in st.session_state:
        init_vertex(st.secrets)
        st.session_state["inited_vertex"] = True
else:
    st.error("éäº‘ç«¯ç¯å¢ƒï¼Œæ— æ³•ä½¿ç”¨ Vertex AI")
    st.stop()

# endregion

# region å¸¸é‡

current_cwd: Path = Path(__file__).parent.parent
voices_fp = current_cwd / "resource" / "voices.json"
audio_dir = current_cwd / "resource" / "audio_data"

if not os.path.exists(audio_dir):
    os.makedirs(audio_dir, exist_ok=True)

# ä½¿ç”¨ä¸´æ—¶æ–‡ä»¶
replay_fp = os.path.join(audio_dir, f"{st.session_state.user_id}-tab2-replay.wav")
listen_fp = os.path.join(audio_dir, f"{st.session_state.user_id}-tab2-listen.wav")

# region templates

WORD_TOOLTIP_TEMPLATE = """\
<table>\
    <tr>\
        <td colspan="{n}">{word_score}</td>\
    </tr>\
    <tr>\
        {phoneme_cols}\
    </tr>\
    <tr>\
        {score_cols}\
    </tr>\
</table>\
"""

BADGE_TEMPLATE = """
<button type="button" class="btn btn-{btn_class}" data-bs-toggle="tooltip" data-bs-placement="top"
        data-bs-custom-class="custom-tooltip"
        data-bs-title="{title}">
  {label} <span class="badge text-bg-{color}">{num}</span>
</button>
"""

# BTN_TEMPLATE = """
# <button type="button" class="btn {btn_class}"
#         data-tippy-content="{title}">
#   {label}
# </button>
# """
BTN_TEMPLATE = """
<button type="button" class="btn {btn_class}" data-bs-placement="top"
        data-tippy-content="{title}">
  {label}
</button>
"""

# endregion

# endregion

# region ä¼šè¯çŠ¶æ€

if "assessment_tb2" not in st.session_state:
    st.session_state["assessment_tb2"] = {}

if "tab2_topics" not in st.session_state:
    st.session_state["tab2_topics"] = []

# endregion

# region å‡½æ•°


def reset_topics():
    level = st.session_state["ps_level"]
    category = st.session_state["ps_category"]
    st.session_state["tab2_topics"] = generate_english_topics(
        "æµ‹è¯•è‹±è¯­å£è¯­æ°´å¹³", category, level
    )


@st.cache_data
def get_synthesize_speech(text, voice):
    synthesize_speech_to_file(
        text,
        listen_fp,
        st.secrets["Microsoft"]["SPEECH_KEY"],
        st.secrets["Microsoft"]["SPEECH_REGION"],
        voice,
    )


def update_mav(audio):
    # audio is the variable containing the audio data
    with wave.open(replay_fp, "w") as wav_file:
        wav_file.setnchannels(1)
        wav_file.setsampwidth(audio["sample_width"])
        wav_file.setframerate(audio["sample_rate"])
        wav_file.writeframes(audio["bytes"])


def get_bg_color(score):
    if score < 60:
        return "bg-danger"
    elif score < 80:
        return "bg-warning"
    else:
        return "bg-success"


def get_cp_color(score):
    if score < 60:
        return "#c02a2a"
    elif score < 80:
        return "yellow"
    else:
        return "green"


def generate_score_legend():
    """
    Returns an HTML string representing a score legend for Tippy game.

    The legend displays three color-coded ranges of scores:
    - 0 ~ 59: red
    - 60 ~ 79: yellow
    - 80 ~ 100: green

    Returns:
    str: An HTML string representing the score legend.
    """
    return """\
<div style="display: flex; align-items: center;">\
    <div style="width: 12px; height: 12px; background-color: #c02a2a; margin-right: 6px; margin-left: 6px;"></div>\
    <span>0 ~ 59</span>\
    <div style="width: 12px; height: 12px; background-color: yellow; margin-right: 6px;margin-left: 6px;"></div>\
    <span>60 ~ 79</span>\
    <div style="width: 12px; height: 12px; background-color: green; margin-right: 6px;margin-left: 6px;"></div>\
    <span>80 ~ 100</span>\
</div>\
"""


def generate_word_tooltip(word) -> str:
    """
    ç”Ÿæˆå•è¯çš„å·¥å…·æç¤ºã€‚

    Args:
        word (str): å•è¯çš„å­—ç¬¦ä¸²ã€‚
        definition (str): å•è¯çš„å®šä¹‰å­—ç¬¦ä¸²ã€‚

    Returns:
        tooltip (str): åŒ…å«å•è¯å’Œå®šä¹‰çš„HTMLå·¥å…·æç¤ºå­—ç¬¦ä¸²ã€‚
    """
    res = ""
    n = len(word.phonemes)
    word_score = f"{word.word} : {int(word.accuracy_score)}"
    phoneme_cols = """ """.join(
        [f"""<td>{p.phoneme}&nbsp;</td>""" for p in word.phonemes]
    )
    score_cols = """ """.join(
        [f"""<td>{int(p.accuracy_score)}&nbsp;</td>""" for p in word.phonemes]
    )
    res = WORD_TOOLTIP_TEMPLATE.format(
        n=n, word_score=word_score, phoneme_cols=phoneme_cols, score_cols=score_cols
    )
    return res


# region æ ‡å¤´

MD_BADGE_MAPS = OrderedDict(
    {
        "None": ("green", "å‘éŸ³ä¼˜ç§€", "å‘éŸ³ä¼˜ç§€çš„å­—è¯", "success"),
        "Mispronunciation": ("orange", "å‘éŸ³é”™è¯¯", "è¯´å¾—ä¸æ­£ç¡®çš„å­—è¯", "warning"),
        # "Omission": ("grey", "é—æ¼å­—è¯", "è„šæœ¬ä¸­å·²æä¾›ï¼Œä½†æœªè¯´å‡ºçš„å­—è¯", "secondary"),
        # "Insertion": ("red", "æ’å…¥å†…å®¹", "ä¸åœ¨è„šæœ¬ä¸­ä½†åœ¨å½•åˆ¶ä¸­æ£€æµ‹åˆ°çš„å­—è¯", "danger"),
        "UnexpectedBreak": ("violet", "æ„å¤–ä¸­æ–­", "åŒä¸€å¥å­ä¸­çš„å•è¯ä¹‹é—´æœªæ­£ç¡®æš‚åœ", "info"),
        "MissingBreak": ("blue", "ç¼ºå°‘åœé¡¿", "å½“ä¸¤ä¸ªå•è¯ä¹‹é—´å­˜åœ¨æ ‡ç‚¹ç¬¦å·æ—¶ï¼Œè¯ä¹‹é—´ç¼ºå°‘æš‚åœ", "light"),
        "Monotone": ("rainbow", "å•è°ƒå‘éŸ³", "è¿™äº›å•è¯æ­£ä»¥å¹³æ·¡ä¸”ä¸å…´å¥‹çš„è¯­è°ƒé˜…è¯»ï¼Œæ²¡æœ‰ä»»ä½•èŠ‚å¥æˆ–è¡¨è¾¾", "dark"),
    }
)

MD_BADGE_TEMPLATE = """
<button type="button" class="btn btn-{btn_class}" data-bs-toggle="tooltip" data-bs-placement="top"
        data-bs-custom-class="custom-tooltip"
        data-bs-title="{title}">
  {label} <span class="badge text-bg-{color}">{num}</span>
</button>
"""


def view_md_badges():
    assessment = st.session_state["assessment_tb2"]
    cols = st.columns(len(MD_BADGE_MAPS.keys()) + 2)
    error_counts = assessment.get("error_counts", {})
    for i, t in enumerate(MD_BADGE_MAPS.keys()):
        num = f"{error_counts.get(t,0):3d}"
        body = f"""{MD_BADGE_MAPS[t][1]}({num})"""
        cols[i].markdown(
            f""":{MD_BADGE_MAPS[t][0]}[{body}]""",
            help=MD_BADGE_MAPS[t][2],
        )


# endregion


# region å•è¯å‘éŸ³

MD_BTN_TEMPLATE = """
<button class="btn-{btn_class}" data-tippy-content="{title}">
  {label}
</button>
"""


def fmt_word(text: str, err_type: str):
    """
    Formats a word based on the error type.

    Args:
        text (str): The word to format.
        err_type (str): The type of error.

    Returns:
        str: The formatted word.
    """
    t = err_type.lower()
    match t:
        case "mispronunciation":
            return f"""<span class="text-decoration-underline">{text}</span>"""
        case "omission":
            return f"""[{text}]"""
        case "pause":
            return f"""[{text}]"""
        case "insertion":
            return f"""<span class="text-decoration-line-through">{text}</span>"""
        case "interruption":
            return f"""<span class="text-decoration-line-through">[{text}]</span>"""
        case "monotone":
            return f"""<span class="text-decoration-overline">[{text}]</span>"""
        case _:
            return f"""{text}"""


def view_word_pronunciation():
    assessment = st.session_state["assessment_tb2"]
    words_list = assessment.get("words_list", [])
    html = ""
    for word in words_list:
        error_type = f"{word.error_type}"
        # print(error_type)
        # btn_class = (
        #     f"""{MD_BADGE_MAPS[error_type][3]}""" if error_type != "success" else ""
        # )
        btn_class = f"""{MD_BADGE_MAPS[error_type][3]}"""
        label = fmt_word(word.word, error_type)
        # è§£å†³å•å¼•å·ã€åŒå¼•å·é—®é¢˜
        title = generate_word_tooltip(word).replace("'", "&#39;").replace('"', "&quot;")
        btn = MD_BTN_TEMPLATE.format(
            btn_class=btn_class,
            title=title,
            label=label,
        )
        # st.write(btn)
        html += btn
    html = f"""<p>{html}</p>"""
    components.html(STYLE + html + TIPPY_JS, height=300, scrolling=True)


# endregion

# region é›·è¾¾å›¾


def view_radar():
    cols = st.columns(2)
    # é›·è¾¾å›¾
    item_1 = {
        "pronunciation_score": "å‘éŸ³æ€»è¯„åˆ†",
        "accuracy_score": "å‡†ç¡®æ€§è¯„åˆ†",
        "completeness_score": "å®Œæ•´æ€§è¯„åˆ†",
        "fluency_score": "æµç•…æ€§è¯„åˆ†",
        "prosody_score": "éŸµå¾‹åˆ†æ•°",
    }
    data_1 = {key: st.session_state.assessment_tb2.get(key, 0) for key in item_1.keys()}
    with cols[0]:
        gen_radar(data_1, item_1, 320)

    content_result = st.session_state.assessment_tb2.get("content_result", {})
    item_2 = {
        "content_score": "å†…å®¹åˆ†æ•°",
        "grammar_score": "è¯­æ³•åˆ†æ•°",
        "vocabulary_score": "è¯æ±‡åˆ†æ•°",
        "topic_score": "ä¸»é¢˜åˆ†æ•°",
    }
    data_2 = {key: getattr(content_result, key, 0) for key in item_2.keys()}
    data_2["content_score"] = (
        data_2["grammar_score"] + data_2["vocabulary_score"] + data_2["topic_score"]
    ) / 3
    with cols[1]:
        gen_radar(data_2, item_2, 320)


# endregion

# region å‘éŸ³è¯„ä¼°æŠ¥å‘Š


def view_report():
    # å‘éŸ³è¯„ä¼°æŠ¥å‘Š
    view_md_badges()
    st.divider()
    view_word_pronunciation()
    view_radar()


# endregion


def view_score_legend(progress_cols, add_spinner=False):
    with progress_cols[0]:
        st.markdown(
            "**å‘éŸ³åˆ†æ•°**",
            help="è¡¨ç¤ºç»™å®šè¯­éŸ³å‘éŸ³è´¨é‡çš„æ€»ä½“åˆ†æ•°ã€‚å®ƒæ˜¯ä» AccuracyScoreã€FluencyScoreã€CompletenessScoreã€Weight æŒ‰æƒé‡èšåˆçš„ã€‚",
        )
    with progress_cols[1]:
        st.markdown(
            "å‡†ç¡®æ€§è¯„åˆ†",
            help="è¯­éŸ³çš„å‘éŸ³å‡†ç¡®æ€§ã€‚å‡†ç¡®æ€§è¡¨ç¤ºéŸ³ç´ ä¸æ¯è¯­è¯´è¯äººçš„å‘éŸ³çš„åŒ¹é…ç¨‹åº¦ã€‚å­—è¯å’Œå…¨æ–‡çš„å‡†ç¡®æ€§å¾—åˆ†æ˜¯ç”±éŸ³ç´ çº§çš„å‡†ç¡®åº¦å¾—åˆ†æ±‡æ€»è€Œæ¥ã€‚",
        )
    with progress_cols[2]:
        st.markdown(
            "å®Œæ•´æ€§è¯„åˆ†",
            help="è¯­éŸ³çš„å®Œæ•´æ€§ï¼ŒæŒ‰å‘éŸ³å•è¯ä¸è¾“å…¥å¼•ç”¨æ–‡æœ¬çš„æ¯”ç‡è®¡ç®—ã€‚",
        )
    with progress_cols[3]:
        st.markdown(
            "æµç•…æ€§è¯„åˆ†",
            help="ç»™å®šè¯­éŸ³çš„æµç•…æ€§ã€‚æµç•…æ€§è¡¨ç¤ºè¯­éŸ³ä¸æ¯è¯­è¯´è¯äººåœ¨å•è¯é—´çš„åœé¡¿ä¸Šæœ‰å¤šæ¥è¿‘ã€‚",
        )
    with progress_cols[4]:
        st.markdown(
            "éŸµå¾‹åˆ†æ•°",
            help="ç»™å®šè¯­éŸ³çš„éŸµå¾‹ã€‚éŸµå¾‹æŒ‡ç¤ºç»™å®šè¯­éŸ³çš„æ€§è´¨ï¼ŒåŒ…æ‹¬é‡éŸ³ã€è¯­è°ƒã€è¯­é€Ÿå’ŒèŠ‚å¥ã€‚",
        )
    score_legend = generate_score_legend()
    # if add_spinner:
    #     score_legend += "<hr>"
    components.html(STYLE + score_legend)


# endregion

# region é¡µé…ç½®

st.set_page_config(
    page_title="è¯„ä¼°å‘éŸ³ä¸å¯¹è¯",
    page_icon="ğŸ—£ï¸",
    layout="wide",
)

if not st.session_state.dbi.is_service_active(st.session_state["user_id"]):
    st.error("æ‚¨å°šæœªä»˜è´¹ï¼Œæ— æ³•ä½¿ç”¨æ­¤åŠŸèƒ½ã€‚")
    st.stop()

# endregion

# region è¾¹æ 

language = "en-US"

with open(voices_fp, "r", encoding="utf-8") as f:
    names = json.load(f)[language]
voice_style: Any = st.sidebar.selectbox(
    "åˆæˆè¯­éŸ³é£æ ¼", names, format_func=lambda x: f"{x[2]}ã€{x[1]}ã€‘"
)

level_selectbox = st.sidebar.selectbox(
    "æ‚¨å½“å‰çš„è‹±è¯­æ°´å¹³",
    CEFR_LEVEL_MAPS.keys(),
    format_func=lambda x: CEFR_LEVEL_MAPS[x],
    on_change=reset_topics,
    key="ps_level",
    help="åœºæ™¯è¯é¢˜ä¼šæ ¹æ®æ‚¨çš„é€‰æ‹©æ¥åŒ¹é…éš¾åº¦",
)
topic_selectbox = st.sidebar.selectbox(
    "ä¸»é¢˜",
    TOPICS["zh-CN"],
    key="ps_category",
    on_change=reset_topics,
    help="é€‰æ‹©ä¸»é¢˜ï¼ŒAIç”Ÿæˆè¯é¢˜ä¾›æ‚¨é€‰æ‹©",
)


# endregion

# region äº‹ä»¶


def reset_tb2():
    # get_synthesize_speech.clear()
    st.session_state["assessment_tb2"] = {}
    st.session_state["text_tb2"] = ""
    if os.path.exists(replay_fp):
        os.remove(replay_fp)


# def on_tb1_text_changed():
#     if os.path.exists(replay_fp):
#         os.remove(replay_fp)


@st.cache_data(show_spinner="ä½¿ç”¨ Azure æœåŠ¡è¯„ä¼°å¯¹è¯...")
def pronunciation_assessment_func(topic):
    try:
        st.session_state[
            "assessment_tb2"
        ] = pronunciation_assessment_with_content_assessment(
            replay_fp,
            topic,
            language,
            st.secrets["Microsoft"]["SPEECH_KEY"],
            st.secrets["Microsoft"]["SPEECH_REGION"],
        )
    except Exception as e:
        st.toast(e)
        st.stop()


def on_ass_btn_click(topic):
    pronunciation_assessment_func(topic)
    # æ˜¾ç¤ºè¯†åˆ«çš„æ–‡æœ¬
    st.session_state["text_tb2"] = st.session_state.assessment_tb2["recognized_text"]
    st.session_state["record_ready"] = False


def _get_cn_name(lan):
    for k, v in LAN_MAPS.items():
        if k.startswith(lan):
            return v


def on_ai_btn_click(text_to_be_evaluated_tb1, voice_style, placeholder):
    try:
        get_synthesize_speech(text_to_be_evaluated_tb1, voice_style[0])
    except Exception as e:
        placeholder.error(e)
        st.stop()


# endregion

# region å‘éŸ³è¯„ä¼°


page_emoji = "ğŸ—£ï¸"
st.markdown(
    f"""#### {page_emoji} å£è¯­è¯„ä¼°
è‹±è¯­å£è¯­è¯„ä¼°æ˜¯å¸®åŠ©å­¦ä¹ è€…äº†è§£è‡ªå·±çš„å£è¯­æ°´å¹³ï¼Œå¹¶é’ˆå¯¹æ€§åœ°è¿›è¡Œç»ƒä¹ çš„é‡è¦å·¥å…·ã€‚æœ¬äº§å“åŸºäº`Azure`è¯­éŸ³æœåŠ¡ï¼Œå€ŸåŠ©`Google Vertex AI`ï¼Œæä¾›å£è¯­è¯„ä¼°å’ŒAIè¾…åŠ©æ•™å­¦åŠŸèƒ½ã€‚

ä½¿ç”¨æ–¹æ³•å¦‚ä¸‹ï¼š
1. è¯·ä½¿ç”¨ğŸ‘ˆå·¦ä¾§èœå•æ¥è®¾ç½®æ‚¨çš„è‹±è¯­æ°´å¹³å’Œè¦è®¨è®ºçš„é¢†åŸŸã€‚
2. åŸºäºæ‚¨çš„è®¾ç½®ï¼ŒAIå°†è‡ªåŠ¨ç”Ÿæˆå£è¯­è¯„ä¼°è¯é¢˜ã€‚æ‚¨å¯ä»¥ä½¿ç”¨ğŸ‘‡ä¸‹æ‹‰æ¡†é€‰æ‹©æ‚¨æ„¿æ„è®¨è®ºçš„è¯é¢˜ã€‚
3. å‡†å¤‡å°±ç»ªåï¼Œæ‚¨å¯ä»¥ä½¿ç”¨éº¦å…‹é£å¼€å§‹å½•åˆ¶å…³äºè¯¥ä¸»é¢˜çš„è®¨è®ºï¼Œä¹Ÿå¯ä»¥ç›´æ¥ä¸Šä¼ æ‚¨å·²å½•åˆ¶å¥½çš„éŸ³é¢‘ã€‚
4. ç‚¹å‡»â€œè¯„ä¼°â€æŒ‰é’®ï¼ŒæŸ¥çœ‹å‘éŸ³è¯„ä¼°æŠ¥å‘Šã€‚è¯¥æŠ¥å‘ŠåŒ…æ‹¬å‘éŸ³å¾—åˆ†ã€è¯æ±‡å¾—åˆ†ã€è¯­æ³•å¾—åˆ†å’Œä¸»é¢˜å¾—åˆ†ã€‚
5. ç‚¹å‡»â€œæ ·ä¾‹â€æŒ‰é’®ï¼Œåˆæˆé€‰å®šçš„è¯­éŸ³é£æ ¼ï¼Œç”Ÿæˆå‚è€ƒç¤ºä¾‹ã€‚
6. ç‚¹å‡»â€œè†å¬â€æŒ‰é’®ï¼Œè†å¬åˆæˆè¯­éŸ³ã€‚
"""
)

# åˆå§‹åŒ–
if len(st.session_state["tab2_topics"]) == 0:
    st.session_state["tab2_topics"] = generate_english_topics(
        "æµ‹è¯•è‹±è¯­å£è¯­æ°´å¹³", topic_selectbox, level_selectbox
    )

topic = st.selectbox("è¯é¢˜", st.session_state["tab2_topics"], key="topic_tb2")

st.text_area(
    "ğŸ“ **è¯†åˆ«çš„æ–‡æœ¬**",
    key="text_tb2",
    max_chars=2000,
    height=200,
    label_visibility="collapsed",
    disabled=True,
    # on_change=on_tb1_text_changed,
    placeholder="è¯†åˆ«çš„æ–‡æœ¬",
    help="è¯†åˆ«çš„æ–‡æœ¬",
)

message_placeholder = st.empty()
st.info("è¦æ±‚ï¼šæ—¶é•¿è¶…è¿‡15ç§’ï¼Œæ–‡å­—ç¯‡å¹…åœ¨50ä¸ªå­—è¯å’Œ3ä¸ªå¥å­ä»¥ä¸Šã€‚")
uploaded_file = st.file_uploader("ğŸ“ ä¸Šä¼ éŸ³é¢‘", type=["wav"], help="ä¸Šä¼ æ‚¨å½•åˆ¶çš„éŸ³é¢‘æ–‡ä»¶")

btn_num = 8
btn_cols = st.columns(btn_num)


with btn_cols[1]:
    audio = mic_recorder(start_prompt="å½•éŸ³[ğŸ”´]", stop_prompt="åœæ­¢[â¹ï¸]", key="recorder")

rep_btn = btn_cols[2].button(
    "å›æ”¾[ğŸ§]",
    key="rep_btn_tb1",
    disabled=not st.session_state.get("record_ready", False),
    help="ç‚¹å‡»æŒ‰é’®ï¼Œæ’­æ”¾éº¦å…‹é£å½•éŸ³æˆ–æ‚¨ä¸Šä¼ çš„éŸ³é¢‘æ–‡ä»¶ã€‚",
)
ass_btn = btn_cols[3].button(
    "è¯„ä¼°[ğŸ”]",
    key="ass_btn_tb1",
    help="ç”Ÿæˆå£è¯­è¯„ä¼°æŠ¥å‘Šã€‚",
    on_click=on_ass_btn_click,
    args=(topic,),
)
syn_btn = btn_cols[4].button(
    "æ ·ä¾‹[ğŸ¤–]",
    key="syn_btn_tb1",
    on_click=on_ai_btn_click,
    help="ç‚¹å‡»æŒ‰é’®åï¼ŒAIå°†ç”Ÿæˆç¤ºä¾‹æ–‡æœ¬ï¼Œå¹¶æ ¹æ®ç”¨æˆ·é€‰æ‹©çš„é£æ ¼åˆæˆè¯­éŸ³ã€‚",
)
lst_btn = btn_cols[5].button("è†å¬[ğŸ‘‚]", key="lst_btn_tab1", help="è†å¬åˆæˆè¯­éŸ³ã€‚")


if uploaded_file is not None:
    st.session_state["record_ready"] = True
    with open(replay_fp, "wb") as f:
        # To read file as string:
        f.write(uploaded_file.read())

if audio:
    # ä¿å­˜wavæ–‡ä»¶
    update_mav(audio)
    st.session_state["record_ready"] = True

if rep_btn:
    if not os.path.exists(replay_fp):
        message_placeholder.warning("æŠ±æ­‰ï¼Œæ‚¨å°šæœªå½•åˆ¶éŸ³é¢‘ï¼Œæ— æ³•å›æ”¾ã€‚")
        st.stop()
    # è‡ªåŠ¨æ’­æ”¾ï¼Œä¸æ˜¾ç¤ºæ§ä»¶
    components.html(audio_autoplay_elem(replay_fp, fmt="mav"), height=0)

if lst_btn:
    if not os.path.exists(listen_fp):
        message_placeholder.warning("æŠ±æ­‰ï¼Œæ‚¨å°šæœªåˆæˆéŸ³é¢‘ï¼Œæ— æ³•è†å¬ã€‚")
        st.stop()
    # è‡ªåŠ¨æ’­æ”¾ï¼Œä¸æ˜¾ç¤ºæ§ä»¶
    components.html(audio_autoplay_elem(listen_fp), height=0)

st.markdown("#### :trophy: è¯„ä¼°ç»“æœ")
view_report()

with st.expander("ğŸ”Š æ“ä½œæç¤º..."):
    st.markdown("å¦‚ä½•è¿›è¡Œå‘éŸ³è¯„ä¼°ğŸ‘‡")
    record_tip = (
        current_cwd / "resource" / "audio_tip" / "cn-pronunciation-assessment-tip.wav"
    )
    st.audio(str(record_tip), format="audio/wav")

    st.markdown("å¦‚ä½•è†å¬å‘éŸ³ç¤ºä¾‹ğŸ‘‡")
    lst_tip = current_cwd / "resource" / "audio_tip" / "cn-synthesis-tip.wav"
    st.audio(str(lst_tip), format="audio/wav")
# endregion
